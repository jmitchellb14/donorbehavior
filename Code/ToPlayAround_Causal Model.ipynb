{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Year</th>\n",
       "      <th>disney_donations</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>disney_donations_lagMinus1</th>\n",
       "      <th>disney_donations_lagPlus1</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_asian</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>ethnicity_islander</th>\n",
       "      <th>ethnicity_native</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>data_use</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>TRAINING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  Year  disney_donations  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  \\\n",
       "0       4  2012               0.0             0.000000               0.333333   \n",
       "1       4  2014               0.0             0.333333               0.800000   \n",
       "2       4  2016               0.0             0.400000               0.428571   \n",
       "3       4  2018            1000.0             1.000000               1.000000   \n",
       "4      10  2012               0.0             0.500000               0.500000   \n",
       "\n",
       "   VoteAlongRatio_FS_FSS  VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  \\\n",
       "0               0.333333              0.571429               0.666667   \n",
       "1               0.333333              0.400000               0.500000   \n",
       "2               0.222222              0.000000               0.000000   \n",
       "3               1.000000              1.000000               1.000000   \n",
       "4               0.666667              0.571429               0.666667   \n",
       "\n",
       "   disney_donations_lagMinus1  disney_donations_lagPlus1  ...  \\\n",
       "0                         0.0                        NaN  ...   \n",
       "1                         0.0                        0.0  ...   \n",
       "2                      1000.0                        0.0  ...   \n",
       "3                         NaN                        0.0  ...   \n",
       "4                      2000.0                        NaN  ...   \n",
       "\n",
       "   ethnicity_asian  ethnicity_black  ethnicity_hispanic  ethnicity_islander  \\\n",
       "0                0                0                   0                   0   \n",
       "1                0                0                   0                   0   \n",
       "2                0                0                   0                   0   \n",
       "3                0                0                   0                   0   \n",
       "4                0                1                   0                   0   \n",
       "\n",
       "   ethnicity_native  ethnicity_white  party_short_D  party_short_R  data_use  \\\n",
       "0                 0                1              1              0     0.727   \n",
       "1                 0                1              1              0     0.727   \n",
       "2                 0                1              1              0     0.727   \n",
       "3                 0                1              1              0     0.727   \n",
       "4                 0                0              1              0     0.086   \n",
       "\n",
       "   MODELING_GROUP  \n",
       "0         TESTING  \n",
       "1         TESTING  \n",
       "2         TESTING  \n",
       "3         TESTING  \n",
       "4        TRAINING  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Data\n",
    "\n",
    "x = \"~/Documents/GitHub/CampaignDonations/Output_Data/MoH_Vote_Data_Long_Sorted_CLEAN.csv\"\n",
    "\n",
    "df = pd.read_csv(x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Year</th>\n",
       "      <th>disney_donations</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>disney_donations_lagMinus1</th>\n",
       "      <th>disney_donations_lagPlus1</th>\n",
       "      <th>...</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ethnicity_asian</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>ethnicity_islander</th>\n",
       "      <th>ethnicity_native</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>data_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  Year  disney_donations  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  \\\n",
       "0       4  2012               0.0             0.000000               0.333333   \n",
       "1       4  2014               0.0             0.333333               0.800000   \n",
       "2       4  2016               0.0             0.400000               0.428571   \n",
       "3       4  2018            1000.0             1.000000               1.000000   \n",
       "4      10  2012               0.0             0.500000               0.500000   \n",
       "\n",
       "   VoteAlongRatio_FS_FSS  VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  \\\n",
       "0               0.333333              0.571429               0.666667   \n",
       "1               0.333333              0.400000               0.500000   \n",
       "2               0.222222              0.000000               0.000000   \n",
       "3               1.000000              1.000000               1.000000   \n",
       "4               0.666667              0.571429               0.666667   \n",
       "\n",
       "   disney_donations_lagMinus1  disney_donations_lagPlus1  ...  sex_male  \\\n",
       "0                         0.0                        NaN  ...         1   \n",
       "1                         0.0                        0.0  ...         1   \n",
       "2                      1000.0                        0.0  ...         1   \n",
       "3                         NaN                        0.0  ...         1   \n",
       "4                      2000.0                        NaN  ...         1   \n",
       "\n",
       "   ethnicity_asian  ethnicity_black  ethnicity_hispanic  ethnicity_islander  \\\n",
       "0                0                0                   0                   0   \n",
       "1                0                0                   0                   0   \n",
       "2                0                0                   0                   0   \n",
       "3                0                0                   0                   0   \n",
       "4                0                1                   0                   0   \n",
       "\n",
       "   ethnicity_native  ethnicity_white  party_short_D  party_short_R  data_use  \n",
       "0                 0                1              1              0     0.727  \n",
       "1                 0                1              1              0     0.727  \n",
       "2                 0                1              1              0     0.727  \n",
       "3                 0                1              1              0     0.727  \n",
       "4                 0                0              1              0     0.086  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('MODELING_GROUP', 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MODELING_GROUP\n",
       "TESTING     126\n",
       "TRAINING    103\n",
       "Name: person, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split Data into Train and Test Sets\n",
    "\n",
    "\n",
    "#create a list of all unique IDs\n",
    "ids=df\n",
    "data_id=ids.drop_duplicates(subset='person')\n",
    "data_id=data_id[['person']]\n",
    "data_id.shape\n",
    "\n",
    "#create new variable with random number between one and zero\n",
    "np.random.seed(42)\n",
    "data_id['data_use'] = (np.random.randint(0, 10000, data_id.shape[0]))/10000\n",
    "data_id=data_id[['person', 'data_use']]\n",
    "\n",
    "#assign each person to a modeling group training or testing with a 50 percent chance \n",
    "\n",
    "data_id['MODELING_GROUP'] = np.where(((data_id.data_use <= 0.50)), 'TRAINING', 'TESTING')\n",
    "\n",
    "\n",
    "groups = data_id.groupby(['MODELING_GROUP'])['person'].count()\n",
    "groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Year</th>\n",
       "      <th>disney_donations</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>disney_donations_lagMinus1</th>\n",
       "      <th>disney_donations_lagPlus1</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>ethnicity_islander</th>\n",
       "      <th>ethnicity_native</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>data_use_x</th>\n",
       "      <th>data_use_y</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.086</td>\n",
       "      <td>TRAINING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  Year  disney_donations  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  \\\n",
       "0       4  2012               0.0             0.000000               0.333333   \n",
       "1       4  2014               0.0             0.333333               0.800000   \n",
       "2       4  2016               0.0             0.400000               0.428571   \n",
       "3       4  2018            1000.0             1.000000               1.000000   \n",
       "4      10  2012               0.0             0.500000               0.500000   \n",
       "\n",
       "   VoteAlongRatio_FS_FSS  VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  \\\n",
       "0               0.333333              0.571429               0.666667   \n",
       "1               0.333333              0.400000               0.500000   \n",
       "2               0.222222              0.000000               0.000000   \n",
       "3               1.000000              1.000000               1.000000   \n",
       "4               0.666667              0.571429               0.666667   \n",
       "\n",
       "   disney_donations_lagMinus1  disney_donations_lagPlus1  ...  \\\n",
       "0                         0.0                        NaN  ...   \n",
       "1                         0.0                        0.0  ...   \n",
       "2                      1000.0                        0.0  ...   \n",
       "3                         NaN                        0.0  ...   \n",
       "4                      2000.0                        NaN  ...   \n",
       "\n",
       "   ethnicity_black  ethnicity_hispanic  ethnicity_islander  ethnicity_native  \\\n",
       "0                0                   0                   0                 0   \n",
       "1                0                   0                   0                 0   \n",
       "2                0                   0                   0                 0   \n",
       "3                0                   0                   0                 0   \n",
       "4                1                   0                   0                 0   \n",
       "\n",
       "   ethnicity_white  party_short_D  party_short_R  data_use_x  data_use_y  \\\n",
       "0                1              1              0       0.727       0.727   \n",
       "1                1              1              0       0.727       0.727   \n",
       "2                1              1              0       0.727       0.727   \n",
       "3                1              1              0       0.727       0.727   \n",
       "4                0              1              0       0.086       0.086   \n",
       "\n",
       "   MODELING_GROUP  \n",
       "0         TESTING  \n",
       "1         TESTING  \n",
       "2         TESTING  \n",
       "3         TESTING  \n",
       "4        TRAINING  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sort_values(by=['person'], ascending=[True])\n",
    "data_id=data_id.sort_values(by=['person'], ascending=[True])\n",
    "df =df.merge(data_id, on=['person'], how='inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS TO MAKE A CAUSAL GRAPH IN PYTHON\n",
    "# import pandas as pd\n",
    "# from dowhy import CausalModel\n",
    "# from IPython.display import Image, display\n",
    "\n",
    "\n",
    "\n",
    "# # set variables \n",
    "# treatment = 'treatment'\n",
    "# outcome = 'loansamt_total'\n",
    "# covariates = [\"members_resid_bl\", \"nadults_resid_bl\", \"head_age_bl\", \"act_livestock_bl\", \"act_business_bl\",\n",
    "#               \"borrowed_total_bl\", \"members_resid_d_bl\", \"nadults_resid_d_bl\", \"head_age_d_bl\",\n",
    "#               \"act_livestock_d_bl\", \"act_business_d_bl\", \"borrowed_total_d_bl\", \"ccm_resp_activ\",\n",
    "#               \"other_resp_activ\", \"ccm_resp_activ_d\", \"other_resp_activ_d\", \"head_educ_1\", \"nmember_age6_16\"]\n",
    "\n",
    "# # build causal graph with dowhy \n",
    "# model = CausalModel(\n",
    "#     data=df,\n",
    "#     treatment=treatment, \n",
    "#     outcome=outcome, \n",
    "#     common_causes=covariates, \n",
    "#     instruments=None, \n",
    "#     effect_modifiers=None)\n",
    "# model.view_model()\n",
    "# display(Image(filename=\"causal_model.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'Year',\n",
       " 'disney_donations',\n",
       " 'VoteAlongRatio_Film',\n",
       " 'VoteAlongRatio_FS_IIR',\n",
       " 'VoteAlongRatio_FS_FSS',\n",
       " 'VoteAlongRatio_FS_CM',\n",
       " 'VoteAlongRatio_FS_REB',\n",
       " 'disney_donations_lagMinus1',\n",
       " 'disney_donations_lagPlus1',\n",
       " 'sex_female',\n",
       " 'sex_male',\n",
       " 'ethnicity_asian',\n",
       " 'ethnicity_black',\n",
       " 'ethnicity_hispanic',\n",
       " 'ethnicity_islander',\n",
       " 'ethnicity_native',\n",
       " 'ethnicity_white',\n",
       " 'party_short_D',\n",
       " 'party_short_R',\n",
       " 'data_use_x',\n",
       " 'data_use_y',\n",
       " 'MODELING_GROUP']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Year</th>\n",
       "      <th>disney_donations</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>disney_donations_lagMinus1</th>\n",
       "      <th>disney_donations_lagPlus1</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>ethnicity_islander</th>\n",
       "      <th>ethnicity_native</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>data_use_x</th>\n",
       "      <th>data_use_y</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "      <th>disney_donations_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.086</td>\n",
       "      <td>TRAINING</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  Year  disney_donations  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  \\\n",
       "0       4  2012               0.0             0.000000               0.333333   \n",
       "1       4  2014               0.0             0.333333               0.800000   \n",
       "2       4  2016               0.0             0.400000               0.428571   \n",
       "3       4  2018            1000.0             1.000000               1.000000   \n",
       "4      10  2012               0.0             0.500000               0.500000   \n",
       "\n",
       "   VoteAlongRatio_FS_FSS  VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  \\\n",
       "0               0.333333              0.571429               0.666667   \n",
       "1               0.333333              0.400000               0.500000   \n",
       "2               0.222222              0.000000               0.000000   \n",
       "3               1.000000              1.000000               1.000000   \n",
       "4               0.666667              0.571429               0.666667   \n",
       "\n",
       "   disney_donations_lagMinus1  disney_donations_lagPlus1  ...  \\\n",
       "0                         0.0                        NaN  ...   \n",
       "1                         0.0                        0.0  ...   \n",
       "2                      1000.0                        0.0  ...   \n",
       "3                         NaN                        0.0  ...   \n",
       "4                      2000.0                        NaN  ...   \n",
       "\n",
       "   ethnicity_hispanic  ethnicity_islander  ethnicity_native  ethnicity_white  \\\n",
       "0                   0                   0                 0                1   \n",
       "1                   0                   0                 0                1   \n",
       "2                   0                   0                 0                1   \n",
       "3                   0                   0                 0                1   \n",
       "4                   0                   0                 0                0   \n",
       "\n",
       "   party_short_D  party_short_R  data_use_x  data_use_y  MODELING_GROUP  \\\n",
       "0              1              0       0.727       0.727         TESTING   \n",
       "1              1              0       0.727       0.727         TESTING   \n",
       "2              1              0       0.727       0.727         TESTING   \n",
       "3              1              0       0.727       0.727         TESTING   \n",
       "4              1              0       0.086       0.086        TRAINING   \n",
       "\n",
       "   disney_donations_dummy  \n",
       "0                     1.0  \n",
       "1                     1.0  \n",
       "2                     2.0  \n",
       "3                     NaN  \n",
       "4                     2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the data:\n",
    "\n",
    "df[\"disney_donations_dummy\"] = df[\"disney_donations_lagMinus1\"]\n",
    "\n",
    "\n",
    "#Create donation-change dummies\n",
    "\n",
    "# 2 for increase in donations\n",
    "# 1 for no change in donations\n",
    "# 0 for decline in donations \n",
    "\n",
    "for x in range(len(df)):\n",
    "    if df[\"disney_donations_dummy\"].iloc[x] > df[\"disney_donations\"].iloc[x]:  \n",
    "        df[\"disney_donations_dummy\"].iloc[x] = 2 \n",
    "    elif  pd.isna(df[\"disney_donations_dummy\"].iloc[x]) == True:\n",
    "        df[\"disney_donations_dummy\"].iloc[x] = df[\"disney_donations_dummy\"].iloc[x] \n",
    "    elif  df[\"disney_donations_dummy\"].iloc[x] < df[\"disney_donations\"].iloc[x]:\n",
    "        df[\"disney_donations_dummy\"].iloc[x] = 0  \n",
    "    else:\n",
    "        df[\"disney_donations_dummy\"].iloc[x] = 1\n",
    "    \n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "treatment = ['VoteAlongRatio_FS_FSS']\n",
    "covariates = [\n",
    " 'Year',\n",
    " 'VoteAlongRatio_Film',\n",
    " 'VoteAlongRatio_FS_IIR',\n",
    " 'VoteAlongRatio_FS_CM',\n",
    " 'VoteAlongRatio_FS_REB',\n",
    " 'sex_female',\n",
    " 'sex_male',\n",
    " 'ethnicity_asian',\n",
    " 'ethnicity_black',\n",
    " 'ethnicity_hispanic',\n",
    " 'ethnicity_islander',\n",
    " 'ethnicity_native',\n",
    " 'ethnicity_white',\n",
    " 'party_short_D',\n",
    " 'party_short_R']\n",
    "outcome = ['disney_donations_dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from dowhy import CausalModel\n",
    "# from IPython.display import Image, display\n",
    "# # build causal graph with dowhy \n",
    "# model = CausalModel(\n",
    "#     data=df,\n",
    "#     treatment=treatment, \n",
    "#     outcome=outcome, \n",
    "#     common_causes=covariates, \n",
    "#     instruments=None, \n",
    "#     effect_modifiers=None)\n",
    "# model.view_model()\n",
    "# display(Image(filename=\"causal_model.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing data \n",
    "from sklearn.model_selection import train_test_split\n",
    "all_variables = treatment+outcome+covariates\n",
    "df = df.dropna(axis=0, subset=all_variables)\n",
    "\n",
    "# # split data into train and test sets \n",
    "# train, test = train_test_split(df, test_size=0.5)\n",
    "test=df.loc[df['MODELING_GROUP']=='TESTING']\n",
    "train=df.loc[df['MODELING_GROUP']=='TRAINING']\n",
    "\n",
    "# set variables for causal forest Y=outcome, T=treatment, X=covariates, W=effect_modifiers \n",
    "Y = train[outcome]\n",
    "T = train[treatment]\n",
    "X = train[covariates]\n",
    "W = None\n",
    "X_test = test[covariates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: econml in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (0.10.0)\n",
      "Requirement already satisfied: joblib>=0.13.0 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (0.17.0)\n",
      "Requirement already satisfied: pandas in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (1.1.3)\n",
      "Requirement already satisfied: scipy>1.4.0 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (1.5.2)\n",
      "Requirement already satisfied: statsmodels>=0.9 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (0.12.0)\n",
      "Requirement already satisfied: numpy in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (1.19.2)\n",
      "Requirement already satisfied: graphviz in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (0.16)\n",
      "Requirement already satisfied: shap~=0.38.1 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (0.38.1)\n",
      "Requirement already satisfied: numba!=0.42.1 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (0.51.2)\n",
      "Requirement already satisfied: dowhy in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (0.6)\n",
      "Requirement already satisfied: sparse in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (0.12.0)\n",
      "Requirement already satisfied: scikit-learn>0.22.0 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from econml) (0.24.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from pandas->econml) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from pandas->econml) (2.8.1)\n",
      "Requirement already satisfied: patsy>=0.5 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from statsmodels>=0.9->econml) (0.5.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from shap~=0.38.1->econml) (1.6.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from shap~=0.38.1->econml) (0.0.7)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from shap~=0.38.1->econml) (4.50.2)\n",
      "Requirement already satisfied: setuptools in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from numba!=0.42.1->econml) (50.3.1.post20201107)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from numba!=0.42.1->econml) (0.34.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from dowhy->econml) (2.5)\n",
      "Requirement already satisfied: pydot>=1.4 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from dowhy->econml) (1.4.2)\n",
      "Requirement already satisfied: sympy>=1.4 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from dowhy->econml) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>0.22.0->econml) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->econml) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from networkx>=2.0->dowhy->econml) (4.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from pydot>=1.4->dowhy->econml) (2.4.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/georg/opt/anaconda3/lib/python3.8/site-packages (from sympy>=1.4->dowhy->econml) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08039871]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from econml.dml import CausalForestDML\n",
    "from sklearn.linear_model import MultiTaskLassoCV\n",
    "\n",
    "# set parameters for causal forest \n",
    "causal_forest = CausalForestDML(criterion='het', \n",
    "                                n_estimators=100,       \n",
    "                                min_samples_leaf=10, \n",
    "                                max_depth=3, \n",
    "                                max_samples=0.4,\n",
    "                                discrete_treatment=False,\n",
    "                                honest=True,\n",
    "                                inference=True,\n",
    "                                cv=10,\n",
    "                                model_t=MultiTaskLassoCV(), \n",
    "                                model_y=MultiTaskLassoCV(),\n",
    "                                )\n",
    "                      \n",
    "# fit train data to causal forest model \n",
    "causal_forest.fit(Y, T, X=X, W=W)\n",
    "# estimate the CATE with the test set \n",
    "causal_forest.const_marginal_ate(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "# from econml.dml import CausalForestDML\n",
    "\n",
    "# # fit causal forest with default parameters \n",
    "# causal_forest = CausalForestDML()\n",
    "# causal_forest.fit(Y, T, X=X, W=W)\n",
    "\n",
    "# # calculate shap values of causal forest model\n",
    "# shap_values = causal_forest.shap_values(X)\n",
    "# # plot shap values \n",
    "# shap.summary_plot(shap_values['Y0']['T0'])\n",
    "\n",
    "\n",
    "from econml.cate_interpreter import SingleTreePolicyInterpreter\n",
    "# We find a tree-based treatment policy based on the CATE model\n",
    "intrp = SingleTreePolicyInterpreter(risk_level=0.05, max_depth=3, min_samples_leaf=1,min_impurity_decrease=.001)\n",
    "intrp.interpret(causal_forest, X, sample_treatment_costs=0.2)\n",
    "# Plot the tree\n",
    "plt.figure(figsize=(25, 5))\n",
    "intrp.plot(feature_names=['A', 'B', 'C', 'D'], fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use causal forest model to estimate treatment effects  \n",
    "treatment_effects = causal_forest.effect(X)\n",
    "# calculate lower bound and upper bound confidence intervals \n",
    "lb, ub = causal_forest.effect_interval(X, alpha=0.05)\n",
    "\n",
    "# convert arrays to pandas dataframes for plotting\n",
    "te_df = pd.DataFrame(treatment_effects, columns=['cate'])\n",
    "lb_df = pd.DataFrame(lb, columns=['lb'])\n",
    "ub_df = pd.DataFrame(ub, columns=['ub'])\n",
    "\n",
    "# merge dataframes and sort \n",
    "df = te_df.merge(lb_df, left_on=te_df.index, right_on=lb_df.index, how='left')\n",
    "df.drop(columns=['key_0'], inplace=True)\n",
    "df = df.merge(ub_df, left_on=df.index, right_on=ub_df.index, how='left')\n",
    "df.drop(columns=['key_0'], inplace=True)\n",
    "df.sort_values('cate', inplace=True, ascending=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# calculate rolling mean\n",
    "z = df.rolling(window=30, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f827fa27610>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set plot size\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# plot lines for treatment effects and confidence intervals\n",
    "ax.plot(z['cate'],\n",
    "        marker='.', linestyle='-', linewidth=0.5, label='CATE', color='indigo')\n",
    "ax.plot(z['lb'],\n",
    "        marker='.', linestyle='-', linewidth=0.5, color='steelblue')\n",
    "ax.plot(z['ub'],\n",
    "        marker='.', linestyle='-', linewidth=0.5, color='steelblue')\n",
    "# label axes and create legend\n",
    "ax.set_ylabel('Treatment Effects')\n",
    "ax.set_xlabel('Number of observations')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.cate_interpreter import SingleTreeCateInterpreter\n",
    "intrp = SingleTreeCateInterpreter(include_model_uncertainty=True, max_depth=3, min_samples_leaf=10)\n",
    "# We interpret the CATE model's behavior based on the features used for heterogeneity\n",
    "intrp.interpret(causal_forest, X)\n",
    "# Plot the tree\n",
    "plt.figure(figsize=(50, 15))\n",
    "intrp.plot(feature_names=['Year',\n",
    " 'VoteAlongRatio_Film',\n",
    " 'VoteAlongRatio_FS_IIR',\n",
    " 'VoteAlongRatio_FS_CM',\n",
    " 'VoteAlongRatio_FS_REB',\n",
    " 'disney_donations_dummy',\n",
    " 'sex_female',\n",
    " 'sex_male',\n",
    " 'ethnicity_asian',\n",
    " 'ethnicity_black',\n",
    " 'ethnicity_hispanic',\n",
    " 'ethnicity_islander',\n",
    " 'ethnicity_native',\n",
    " 'ethnicity_white',\n",
    " 'party_short_D',\n",
    " 'party_short_R'], fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
