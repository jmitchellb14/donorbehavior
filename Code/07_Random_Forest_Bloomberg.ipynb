{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a Random Forest as Baseline and for Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: MoH_Vote_Data_Long_Sorted.csv \n",
    "# Contains Donation Data by Disney and the rations of voting along party line in 5 categories over 4 sessios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Year</th>\n",
       "      <th>party_short</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sex</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>Bloomberg_Donations</th>\n",
       "      <th>Citadel_Donations</th>\n",
       "      <th>Bloomberg_donations_lagMinus1</th>\n",
       "      <th>Citadel_donations_lagMinus1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>R</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person  Year party_short ethnicity     sex  VoteAlongRatio_Film  \\\n",
       "0        0  2012           R     white    male             0.750000   \n",
       "1        0  2014           R     white    male             0.666667   \n",
       "2        0  2016           R     white    male             0.800000   \n",
       "3        0  2018           R     white    male             0.000000   \n",
       "4        1  2012           R     white  female             0.750000   \n",
       "5        1  2014           R     white  female             1.000000   \n",
       "6        1  2016           R     white  female             0.600000   \n",
       "7        1  2018           R     white  female             0.000000   \n",
       "8        2  2012           R     white    male             0.500000   \n",
       "9        2  2014           R     white    male             1.000000   \n",
       "10       2  2016           R     white    male             0.600000   \n",
       "11       2  2018           R     white    male             0.500000   \n",
       "12       3  2012           R     white    male             0.750000   \n",
       "13       3  2014           R     white    male             0.000000   \n",
       "14       3  2016           R     white    male             0.000000   \n",
       "15       3  2018           R     white    male             0.000000   \n",
       "16       4  2012           R     white    male             1.000000   \n",
       "17       4  2014           R     white    male             0.666667   \n",
       "18       4  2016           R     white    male             0.800000   \n",
       "19       4  2018           R     white    male             0.000000   \n",
       "\n",
       "    VoteAlongRatio_FS_IIR  VoteAlongRatio_FS_FSS  VoteAlongRatio_FS_CM  \\\n",
       "0                0.000000               0.000000              0.000000   \n",
       "1                0.800000               0.333333              0.600000   \n",
       "2                0.857143               0.888889              1.000000   \n",
       "3                0.500000               0.333333              1.000000   \n",
       "4                0.833333               0.666667              0.714286   \n",
       "5                0.800000               0.333333              0.600000   \n",
       "6                0.857143               0.777778              1.000000   \n",
       "7                0.500000               0.333333              1.000000   \n",
       "8                0.833333               0.333333              0.714286   \n",
       "9                0.800000               0.333333              0.600000   \n",
       "10               0.857143               0.888889              1.000000   \n",
       "11               0.500000               0.333333              1.000000   \n",
       "12               0.833333               0.666667              0.714286   \n",
       "13               0.000000               0.000000              0.000000   \n",
       "14               0.000000               0.000000              0.000000   \n",
       "15               0.000000               0.000000              1.000000   \n",
       "16               1.000000               1.000000              0.571429   \n",
       "17               1.000000               0.666667              0.800000   \n",
       "18               0.857143               0.777778              1.000000   \n",
       "19               0.500000               0.333333              1.000000   \n",
       "\n",
       "    VoteAlongRatio_FS_REB  Bloomberg_Donations  Citadel_Donations  \\\n",
       "0                0.000000                  0.0                0.0   \n",
       "1                0.750000                  0.0                0.0   \n",
       "2                1.000000                  0.0                0.0   \n",
       "3                0.333333                  0.0                0.0   \n",
       "4                0.333333                  0.0                0.0   \n",
       "5                0.750000                  0.0                0.0   \n",
       "6                1.000000                  0.0                0.0   \n",
       "7                0.333333                  0.0                0.0   \n",
       "8                0.666667                  0.0                0.0   \n",
       "9                0.750000                  0.0                0.0   \n",
       "10               1.000000                  0.0                0.0   \n",
       "11               0.333333                  0.0                0.0   \n",
       "12               0.666667                  0.0                0.0   \n",
       "13               0.000000                  0.0                0.0   \n",
       "14               0.000000                  0.0                0.0   \n",
       "15               0.000000                  0.0                0.0   \n",
       "16               1.000000                  0.0                0.0   \n",
       "17               1.000000                  0.0                0.0   \n",
       "18               1.000000                  0.0                0.0   \n",
       "19               0.333333                  0.0                0.0   \n",
       "\n",
       "    Bloomberg_donations_lagMinus1  Citadel_donations_lagMinus1  \n",
       "0                             0.0                          0.0  \n",
       "1                             0.0                          0.0  \n",
       "2                             0.0                          0.0  \n",
       "3                             NaN                          NaN  \n",
       "4                             0.0                          0.0  \n",
       "5                             0.0                          0.0  \n",
       "6                             0.0                          0.0  \n",
       "7                             NaN                          NaN  \n",
       "8                             0.0                          0.0  \n",
       "9                             0.0                          0.0  \n",
       "10                            0.0                          0.0  \n",
       "11                            NaN                          NaN  \n",
       "12                            0.0                          0.0  \n",
       "13                            0.0                          0.0  \n",
       "14                            0.0                          0.0  \n",
       "15                            NaN                          NaN  \n",
       "16                            0.0                          0.0  \n",
       "17                            0.0                          0.0  \n",
       "18                            0.0                          0.0  \n",
       "19                            NaN                          NaN  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Data\n",
    "x = \"MoH_Vote_AllDonors_Data_Long_Sorted_New.csv\"\n",
    "df = pd.read_csv(x)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'Year',\n",
       " 'party_short',\n",
       " 'ethnicity',\n",
       " 'sex',\n",
       " 'VoteAlongRatio_Film',\n",
       " 'VoteAlongRatio_FS_IIR',\n",
       " 'VoteAlongRatio_FS_FSS',\n",
       " 'VoteAlongRatio_FS_CM',\n",
       " 'VoteAlongRatio_FS_REB',\n",
       " 'Bloomberg_Donations',\n",
       " 'Citadel_Donations',\n",
       " 'Bloomberg_donations_lagMinus1',\n",
       " 'Citadel_donations_lagMinus1']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "#list = [ 'birth_y', \"religion_y\"]\n",
    "#df = df.drop(columns = list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename some columns\n",
    "#df = df.rename(columns = {'sex_y':\"sex\",  \"ethnicity_y\":'ethnicity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Year</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>Bloomberg_Donations</th>\n",
       "      <th>Citadel_Donations</th>\n",
       "      <th>Bloomberg_donations_lagMinus1</th>\n",
       "      <th>...</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ethnicity_asian</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>ethnicity_islander</th>\n",
       "      <th>ethnicity_native</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_0</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  Year  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  \\\n",
       "0       0  2012             0.750000               0.000000   \n",
       "1       0  2014             0.666667               0.800000   \n",
       "2       0  2016             0.800000               0.857143   \n",
       "3       0  2018             0.000000               0.500000   \n",
       "4       1  2012             0.750000               0.833333   \n",
       "\n",
       "   VoteAlongRatio_FS_FSS  VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  \\\n",
       "0               0.000000              0.000000               0.000000   \n",
       "1               0.333333              0.600000               0.750000   \n",
       "2               0.888889              1.000000               1.000000   \n",
       "3               0.333333              1.000000               0.333333   \n",
       "4               0.666667              0.714286               0.333333   \n",
       "\n",
       "   Bloomberg_Donations  Citadel_Donations  Bloomberg_donations_lagMinus1  ...  \\\n",
       "0                  0.0                0.0                            0.0  ...   \n",
       "1                  0.0                0.0                            0.0  ...   \n",
       "2                  0.0                0.0                            0.0  ...   \n",
       "3                  0.0                0.0                            NaN  ...   \n",
       "4                  0.0                0.0                            0.0  ...   \n",
       "\n",
       "   sex_male  ethnicity_asian  ethnicity_black  ethnicity_hispanic  \\\n",
       "0         1                0                0                   0   \n",
       "1         1                0                0                   0   \n",
       "2         1                0                0                   0   \n",
       "3         1                0                0                   0   \n",
       "4         0                0                0                   0   \n",
       "\n",
       "   ethnicity_islander  ethnicity_native  ethnicity_white  party_short_0  \\\n",
       "0                   0                 0                1              0   \n",
       "1                   0                 0                1              0   \n",
       "2                   0                 0                1              0   \n",
       "3                   0                 0                1              0   \n",
       "4                   0                 0                1              0   \n",
       "\n",
       "   party_short_D  party_short_R  \n",
       "0              0              1  \n",
       "1              0              1  \n",
       "2              0              1  \n",
       "3              0              1  \n",
       "4              0              1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dummines for \"character\"-data\n",
    "df = pd.get_dummies(df, columns = ['sex', 'ethnicity', \"party_short\"])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 1)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Data into Train and Test Sets\n",
    "\n",
    "#create a list of all unique IDs\n",
    "ids=df\n",
    "data_id=ids.drop_duplicates(subset='person')\n",
    "data_id=data_id[['person']]\n",
    "data_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>data_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person  data_use\n",
       "0        0    0.7270\n",
       "4        1    0.0860\n",
       "8        2    0.5390\n",
       "12       3    0.5191\n",
       "16       4    0.5734"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new variable with random number between one and zero\n",
    "\n",
    "np.random.seed(42)\n",
    "data_id['data_use'] = (np.random.randint(0, 10000, data_id.shape[0]))/10000\n",
    "data_id=data_id[['person', 'data_use']]\n",
    "data_id.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>data_use</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>TRAINING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>TRAINING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5191</td>\n",
       "      <td>TRAINING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5734</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person  data_use MODELING_GROUP\n",
       "0        0    0.7270        TESTING\n",
       "4        1    0.0860       TRAINING\n",
       "8        2    0.5390       TRAINING\n",
       "12       3    0.5191       TRAINING\n",
       "16       4    0.5734        TESTING"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign each person to a modeling group training or testing \n",
    "\n",
    "data_id['MODELING_GROUP'] = np.where(((data_id.data_use <= 0.55)), 'TRAINING', 'TESTING')\n",
    "data_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MODELING_GROUP\n",
       "TESTING     133\n",
       "TRAINING    145\n",
       "Name: person, dtype: int64"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = data_id.groupby(['MODELING_GROUP'])['person'].count()\n",
    "groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Year</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>Bloomberg_Donations</th>\n",
       "      <th>Citadel_Donations</th>\n",
       "      <th>Bloomberg_donations_lagMinus1</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>ethnicity_islander</th>\n",
       "      <th>ethnicity_native</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_0</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>data_use</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086</td>\n",
       "      <td>TRAINING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  Year  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  \\\n",
       "0       0  2012             0.750000               0.000000   \n",
       "1       0  2014             0.666667               0.800000   \n",
       "2       0  2016             0.800000               0.857143   \n",
       "3       0  2018             0.000000               0.500000   \n",
       "4       1  2012             0.750000               0.833333   \n",
       "\n",
       "   VoteAlongRatio_FS_FSS  VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  \\\n",
       "0               0.000000              0.000000               0.000000   \n",
       "1               0.333333              0.600000               0.750000   \n",
       "2               0.888889              1.000000               1.000000   \n",
       "3               0.333333              1.000000               0.333333   \n",
       "4               0.666667              0.714286               0.333333   \n",
       "\n",
       "   Bloomberg_Donations  Citadel_Donations  Bloomberg_donations_lagMinus1  ...  \\\n",
       "0                  0.0                0.0                            0.0  ...   \n",
       "1                  0.0                0.0                            0.0  ...   \n",
       "2                  0.0                0.0                            0.0  ...   \n",
       "3                  0.0                0.0                            NaN  ...   \n",
       "4                  0.0                0.0                            0.0  ...   \n",
       "\n",
       "   ethnicity_black  ethnicity_hispanic  ethnicity_islander  ethnicity_native  \\\n",
       "0                0                   0                   0                 0   \n",
       "1                0                   0                   0                 0   \n",
       "2                0                   0                   0                 0   \n",
       "3                0                   0                   0                 0   \n",
       "4                0                   0                   0                 0   \n",
       "\n",
       "   ethnicity_white  party_short_0  party_short_D  party_short_R  data_use  \\\n",
       "0                1              0              0              1     0.727   \n",
       "1                1              0              0              1     0.727   \n",
       "2                1              0              0              1     0.727   \n",
       "3                1              0              0              1     0.727   \n",
       "4                1              0              0              1     0.086   \n",
       "\n",
       "   MODELING_GROUP  \n",
       "0         TESTING  \n",
       "1         TESTING  \n",
       "2         TESTING  \n",
       "3         TESTING  \n",
       "4        TRAINING  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=df.sort_values(by=['person'], ascending=[True])\n",
    "data_id=data_id.sort_values(by=['person'], ascending=[True])\n",
    "df_modelgroups =df.merge(data_id, on=['person'], how='inner')\n",
    "df_modelgroups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Year</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>Bloomberg_Donations</th>\n",
       "      <th>Citadel_Donations</th>\n",
       "      <th>Bloomberg_donations_lagMinus1</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_islander</th>\n",
       "      <th>ethnicity_native</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_0</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>data_use</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "      <th>Bloomberg_Donations_Diff</th>\n",
       "      <th>Citadel_Donations_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086</td>\n",
       "      <td>TRAINING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  Year  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  \\\n",
       "0       0  2012             0.750000               0.000000   \n",
       "1       0  2014             0.666667               0.800000   \n",
       "2       0  2016             0.800000               0.857143   \n",
       "3       0  2018             0.000000               0.500000   \n",
       "4       1  2012             0.750000               0.833333   \n",
       "\n",
       "   VoteAlongRatio_FS_FSS  VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  \\\n",
       "0               0.000000              0.000000               0.000000   \n",
       "1               0.333333              0.600000               0.750000   \n",
       "2               0.888889              1.000000               1.000000   \n",
       "3               0.333333              1.000000               0.333333   \n",
       "4               0.666667              0.714286               0.333333   \n",
       "\n",
       "   Bloomberg_Donations  Citadel_Donations  Bloomberg_donations_lagMinus1  ...  \\\n",
       "0                  0.0                0.0                            0.0  ...   \n",
       "1                  0.0                0.0                            0.0  ...   \n",
       "2                  0.0                0.0                            0.0  ...   \n",
       "3                  0.0                0.0                            NaN  ...   \n",
       "4                  0.0                0.0                            0.0  ...   \n",
       "\n",
       "   ethnicity_islander  ethnicity_native  ethnicity_white  party_short_0  \\\n",
       "0                   0                 0                1              0   \n",
       "1                   0                 0                1              0   \n",
       "2                   0                 0                1              0   \n",
       "3                   0                 0                1              0   \n",
       "4                   0                 0                1              0   \n",
       "\n",
       "   party_short_D  party_short_R  data_use  MODELING_GROUP  \\\n",
       "0              0              1     0.727         TESTING   \n",
       "1              0              1     0.727         TESTING   \n",
       "2              0              1     0.727         TESTING   \n",
       "3              0              1     0.727         TESTING   \n",
       "4              0              1     0.086        TRAINING   \n",
       "\n",
       "   Bloomberg_Donations_Diff  Citadel_Donations_Diff  \n",
       "0                       0.0                     0.0  \n",
       "1                       0.0                     0.0  \n",
       "2                       0.0                     0.0  \n",
       "3                       NaN                     NaN  \n",
       "4                       0.0                     0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#df_modelgroups[\"Disney_Donations_Diff\"] = df_modelgroups[\"disney_donations_lagMinus1\"] - df_modelgroups[\"disney_donations\"]\n",
    "df_modelgroups[\"Bloomberg_Donations_Diff\"] = df_modelgroups[\"Bloomberg_donations_lagMinus1\"] - df_modelgroups[\"Bloomberg_Donations\"]\n",
    "df_modelgroups[\"Citadel_Donations_Diff\"] = df_modelgroups[\"Citadel_donations_lagMinus1\"] - df_modelgroups[\"Citadel_Donations\"]\n",
    "  \n",
    "\n",
    "df_modelgroups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'Year',\n",
       " 'VoteAlongRatio_Film',\n",
       " 'VoteAlongRatio_FS_IIR',\n",
       " 'VoteAlongRatio_FS_FSS',\n",
       " 'VoteAlongRatio_FS_CM',\n",
       " 'VoteAlongRatio_FS_REB',\n",
       " 'Bloomberg_Donations',\n",
       " 'Citadel_Donations',\n",
       " 'Bloomberg_donations_lagMinus1',\n",
       " 'Citadel_donations_lagMinus1',\n",
       " 'sex_female',\n",
       " 'sex_male',\n",
       " 'ethnicity_asian',\n",
       " 'ethnicity_black',\n",
       " 'ethnicity_hispanic',\n",
       " 'ethnicity_islander',\n",
       " 'ethnicity_native',\n",
       " 'ethnicity_white',\n",
       " 'party_short_0',\n",
       " 'party_short_D',\n",
       " 'party_short_R',\n",
       " 'data_use',\n",
       " 'MODELING_GROUP',\n",
       " 'Bloomberg_Donations_Diff',\n",
       " 'Citadel_Donations_Diff']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelgroups.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "list = [ 'data_use', \"party_short_0\", 'Bloomberg_Donations', 'Citadel_Donations',\n",
    "       'Bloomberg_donations_lagMinus1','Citadel_donations_lagMinus1']\n",
    "\n",
    "df_modelgroups= df_modelgroups.drop(columns = list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Year</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ethnicity_asian</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>ethnicity_islander</th>\n",
       "      <th>ethnicity_native</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "      <th>Disney_Donations_Diff</th>\n",
       "      <th>Bloomberg_Donations_Diff</th>\n",
       "      <th>Citadel_Donations_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAINING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  Year  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  \\\n",
       "0       0  2012                  0.0               0.000000   \n",
       "1       0  2014                  0.0               0.000000   \n",
       "2       0  2016                  0.0               0.000000   \n",
       "3       0  2018                  0.0               0.000000   \n",
       "4       1  2012                  0.0               0.333333   \n",
       "\n",
       "   VoteAlongRatio_FS_FSS  VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  \\\n",
       "0               0.000000              0.000000               0.000000   \n",
       "1               0.000000              0.000000               0.000000   \n",
       "2               0.000000              0.000000               0.000000   \n",
       "3               0.000000              1.000000               0.000000   \n",
       "4               0.333333              0.571429               0.666667   \n",
       "\n",
       "   sex_female  sex_male  ethnicity_asian  ...  ethnicity_hispanic  \\\n",
       "0           0         0                0  ...                   0   \n",
       "1           0         0                0  ...                   0   \n",
       "2           0         0                0  ...                   0   \n",
       "3           0         0                0  ...                   0   \n",
       "4           0         0                0  ...                   0   \n",
       "\n",
       "   ethnicity_islander  ethnicity_native  ethnicity_white  party_short_D  \\\n",
       "0                   0                 0                0              1   \n",
       "1                   0                 0                0              1   \n",
       "2                   0                 0                0              1   \n",
       "3                   0                 0                0              1   \n",
       "4                   0                 0                0              1   \n",
       "\n",
       "   party_short_R  MODELING_GROUP Disney_Donations_Diff  \\\n",
       "0              0         TESTING                   NaN   \n",
       "1              0         TESTING                   NaN   \n",
       "2              0         TESTING                   NaN   \n",
       "3              0         TESTING                   NaN   \n",
       "4              0        TRAINING                   NaN   \n",
       "\n",
       "   Bloomberg_Donations_Diff  Citadel_Donations_Diff  \n",
       "0                       NaN                     0.0  \n",
       "1                       NaN                     0.0  \n",
       "2                       NaN                     0.0  \n",
       "3                       NaN                     NaN  \n",
       "4                       NaN                     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelgroups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_modelgroups = df_modelgroups[df_modelgroups[\"Year\"] != 2018]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelgroups = pd.get_dummies(df_modelgroups, columns = ['Year'])\n",
    "\n",
    "df_modelgroups = df_modelgroups.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834, 22)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_modelgroups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #Save Data-Set externally\n",
    "MoH_Vote_Data_Long_Sorted_CLEAN = df_modelgroups\n",
    "compression_opts = dict(method='zip',\n",
    "                       archive_name='MoH_Vote_AllDonors_Data_Long_Sorted_CLEAN_New.csv')  \n",
    "MoH_Vote_Data_Long_Sorted_CLEAN.to_csv('MoH_Vote_AllDonors_Data_Long_Sorted_CLEAN_New.zip', index=False,\n",
    "          compression=compression_opts)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Random Forest Bloomberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: RandomForesetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ethnicity_asian</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "      <th>Disney_Donations_Diff</th>\n",
       "      <th>Bloomberg_Donations_Diff</th>\n",
       "      <th>Citadel_Donations_Diff</th>\n",
       "      <th>Year_2012</th>\n",
       "      <th>Year_2014</th>\n",
       "      <th>Year_2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAINING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAINING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  VoteAlongRatio_FS_FSS  \\\n",
       "0       0             0.000000               0.000000               0.000000   \n",
       "1       0             0.000000               0.000000               0.000000   \n",
       "2       0             0.000000               0.000000               0.000000   \n",
       "4       1             0.000000               0.333333               0.333333   \n",
       "5       1             0.666667               0.600000               0.000000   \n",
       "\n",
       "   VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  sex_female  sex_male  \\\n",
       "0              0.000000               0.000000           0         0   \n",
       "1              0.000000               0.000000           0         0   \n",
       "2              0.000000               0.000000           0         0   \n",
       "4              0.571429               0.666667           0         0   \n",
       "5              0.200000               0.000000           0         0   \n",
       "\n",
       "   ethnicity_asian  ethnicity_black  ...  ethnicity_white  party_short_D  \\\n",
       "0                0                0  ...                0              1   \n",
       "1                0                0  ...                0              1   \n",
       "2                0                0  ...                0              1   \n",
       "4                0                0  ...                0              1   \n",
       "5                0                0  ...                0              1   \n",
       "\n",
       "   party_short_R  MODELING_GROUP  Disney_Donations_Diff  \\\n",
       "0              0         TESTING                    0.0   \n",
       "1              0         TESTING                    0.0   \n",
       "2              0         TESTING                    0.0   \n",
       "4              0        TRAINING                    0.0   \n",
       "5              0        TRAINING                    0.0   \n",
       "\n",
       "   Bloomberg_Donations_Diff Citadel_Donations_Diff  Year_2012  Year_2014  \\\n",
       "0                       0.0                    0.0          1          0   \n",
       "1                       0.0                    0.0          0          1   \n",
       "2                       0.0                    0.0          0          0   \n",
       "4                       0.0                    0.0          1          0   \n",
       "5                       0.0                    0.0          0          1   \n",
       "\n",
       "   Year_2016  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "4          0  \n",
       "5          0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelgroups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ethnicity_asian</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>...</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "      <th>Disney_Donations_Diff</th>\n",
       "      <th>Bloomberg_Donations_Diff</th>\n",
       "      <th>Citadel_Donations_Diff</th>\n",
       "      <th>Year_2012</th>\n",
       "      <th>Year_2014</th>\n",
       "      <th>Year_2016</th>\n",
       "      <th>Bloomberg_Donations_Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAINING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAINING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  VoteAlongRatio_FS_FSS  \\\n",
       "0       0             0.000000               0.000000               0.000000   \n",
       "1       0             0.000000               0.000000               0.000000   \n",
       "2       0             0.000000               0.000000               0.000000   \n",
       "4       1             0.000000               0.333333               0.333333   \n",
       "5       1             0.666667               0.600000               0.000000   \n",
       "\n",
       "   VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  sex_female  sex_male  \\\n",
       "0              0.000000               0.000000           0         0   \n",
       "1              0.000000               0.000000           0         0   \n",
       "2              0.000000               0.000000           0         0   \n",
       "4              0.571429               0.666667           0         0   \n",
       "5              0.200000               0.000000           0         0   \n",
       "\n",
       "   ethnicity_asian  ethnicity_black  ...  party_short_D  party_short_R  \\\n",
       "0                0                0  ...              1              0   \n",
       "1                0                0  ...              1              0   \n",
       "2                0                0  ...              1              0   \n",
       "4                0                0  ...              1              0   \n",
       "5                0                0  ...              1              0   \n",
       "\n",
       "   MODELING_GROUP  Disney_Donations_Diff  Bloomberg_Donations_Diff  \\\n",
       "0         TESTING                    0.0                       0.0   \n",
       "1         TESTING                    0.0                       0.0   \n",
       "2         TESTING                    0.0                       0.0   \n",
       "4        TRAINING                    0.0                       0.0   \n",
       "5        TRAINING                    0.0                       0.0   \n",
       "\n",
       "   Citadel_Donations_Diff Year_2012  Year_2014  Year_2016  \\\n",
       "0                     0.0         1          0          0   \n",
       "1                     0.0         0          1          0   \n",
       "2                     0.0         0          0          1   \n",
       "4                     0.0         1          0          0   \n",
       "5                     0.0         0          1          0   \n",
       "\n",
       "   Bloomberg_Donations_Dummy  \n",
       "0                        1.0  \n",
       "1                        1.0  \n",
       "2                        1.0  \n",
       "4                        1.0  \n",
       "5                        1.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the data:\n",
    "\n",
    "# Dropping all rows that contain \"nan\" in target-column\n",
    "#df_modelgroups = df_modelgroups[df_modelgroups[\"Bloomberg_Donations_Diff\"].notna()]\n",
    "   \n",
    "df_modelgroups[\"Bloomberg_Donations_Dummy\"] = df_modelgroups[\"Bloomberg_Donations_Diff\"]\n",
    "    \n",
    "#Create donation-change dummies\n",
    "\n",
    "# 2 for increase in donations\n",
    "# 1 for no change in donations\n",
    "# 0 for decline in donations \n",
    "\n",
    "for x in range(len(df_modelgroups)):\n",
    "    if df_modelgroups[\"Bloomberg_Donations_Diff\"].iloc[x] == 0:  \n",
    "        df_modelgroups[\"Bloomberg_Donations_Dummy\"].iloc[x] = 1\n",
    "    elif df_modelgroups[\"Bloomberg_Donations_Diff\"].iloc[x] > 0:  \n",
    "        df_modelgroups[\"Bloomberg_Donations_Dummy\"].iloc[x] = 2\n",
    "    elif df_modelgroups[\"Bloomberg_Donations_Diff\"].iloc[x] < 0:  \n",
    "        df_modelgroups[\"Bloomberg_Donations_Dummy\"].iloc[x] = 0\n",
    "\n",
    "    \n",
    "df_modelgroups.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    60\n",
       "Name: sex_0, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#df_modelgroups.sex_0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'VoteAlongRatio_Film',\n",
       " 'VoteAlongRatio_FS_IIR',\n",
       " 'VoteAlongRatio_FS_FSS',\n",
       " 'VoteAlongRatio_FS_CM',\n",
       " 'VoteAlongRatio_FS_REB',\n",
       " 'sex_female',\n",
       " 'sex_male',\n",
       " 'ethnicity_asian',\n",
       " 'ethnicity_black',\n",
       " 'ethnicity_hispanic',\n",
       " 'ethnicity_islander',\n",
       " 'ethnicity_native',\n",
       " 'ethnicity_white',\n",
       " 'party_short_D',\n",
       " 'party_short_R',\n",
       " 'MODELING_GROUP',\n",
       " 'Disney_Donations_Diff',\n",
       " 'Bloomberg_Donations_Diff',\n",
       " 'Citadel_Donations_Diff',\n",
       " 'Year_2012',\n",
       " 'Year_2014',\n",
       " 'Year_2016',\n",
       " 'Bloomberg_Donations_Dummy']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelgroups.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Split dataset (prepare data for splitting)\n",
    "list = [\"person\",   'Disney_Donations_Diff', 'Bloomberg_Donations_Diff', 'Citadel_Donations_Diff']\n",
    "df_modelgroups_split = df_modelgroups.drop(columns=list)\n",
    "\n",
    "# Continue with Splitting\n",
    "X_train = df_modelgroups_split[df_modelgroups_split[\"MODELING_GROUP\"] == \"TRAINING\"]\n",
    "y_train = X_train[[\"Bloomberg_Donations_Dummy\"]]\n",
    "\n",
    "\n",
    "X_test = df_modelgroups_split[df_modelgroups_split[\"MODELING_GROUP\"] == \"TESTING\"]\n",
    "y_test = X_test[[\"Bloomberg_Donations_Dummy\"]]\n",
    "\n",
    "X_train = X_train.drop(columns = [\"MODELING_GROUP\", \"Bloomberg_Donations_Dummy\"])\n",
    "X_test = X_test.drop(columns = [\"MODELING_GROUP\", \"Bloomberg_Donations_Dummy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ethnicity_asian</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>ethnicity_islander</th>\n",
       "      <th>ethnicity_native</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>Year_2012</th>\n",
       "      <th>Year_2014</th>\n",
       "      <th>Year_2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  VoteAlongRatio_FS_FSS  \\\n",
       "4              0.000000               0.333333               0.333333   \n",
       "5              0.666667               0.600000               0.000000   \n",
       "6              0.000000               0.000000               0.000000   \n",
       "9              0.600000               0.428571               0.555556   \n",
       "10             0.750000               0.500000               0.666667   \n",
       "\n",
       "    VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  sex_female  sex_male  \\\n",
       "4               0.571429               0.666667           0         0   \n",
       "5               0.200000               0.000000           0         0   \n",
       "6               0.000000               0.000000           0         0   \n",
       "9               0.250000               0.000000           0         0   \n",
       "10              0.714286               0.666667           0         0   \n",
       "\n",
       "    ethnicity_asian  ethnicity_black  ethnicity_hispanic  ethnicity_islander  \\\n",
       "4                 0                0                   0                   0   \n",
       "5                 0                0                   0                   0   \n",
       "6                 0                0                   0                   0   \n",
       "9                 0                0                   0                   0   \n",
       "10                0                0                   0                   0   \n",
       "\n",
       "    ethnicity_native  ethnicity_white  party_short_D  party_short_R  \\\n",
       "4                  0                0              1              0   \n",
       "5                  0                0              1              0   \n",
       "6                  0                0              1              0   \n",
       "9                  0                0              1              0   \n",
       "10                 0                0              1              0   \n",
       "\n",
       "    Year_2012  Year_2014  Year_2016  \n",
       "4           1          0          0  \n",
       "5           0          1          0  \n",
       "6           0          0          1  \n",
       "9           0          0          1  \n",
       "10          1          0          0  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 1000, max_leaf_nodes = 10,  n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_leaf_nodes=10, n_estimators=1000, n_jobs=-1)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VoteAlongRatio_Film 0.10301604855198847\n",
      "VoteAlongRatio_FS_IIR 0.15042456858731276\n",
      "VoteAlongRatio_FS_FSS 0.10419689382787316\n",
      "VoteAlongRatio_FS_CM 0.10329942544088579\n",
      "VoteAlongRatio_FS_REB 0.0864959517277168\n",
      "sex_female 0.10968782760433082\n",
      "sex_male 0.04401733546655689\n",
      "ethnicity_asian 0.09579483038975556\n",
      "ethnicity_black 0.0355868096591188\n",
      "ethnicity_hispanic 0.005979119386571387\n",
      "ethnicity_islander 0.0\n",
      "ethnicity_native 0.0\n",
      "ethnicity_white 0.06598614057100699\n",
      "party_short_D 0.018390261152320776\n",
      "party_short_R 0.016128235050316422\n",
      "Year_2012 0.01718994599719379\n",
      "Year_2014 0.01657301458287608\n",
      "Year_2016 0.02723359200417537\n"
     ]
    }
   ],
   "source": [
    "# Get Feature Importance \n",
    "\n",
    "for name, score in zip(X_train.columns, rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985632183908046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Get a better tuned model via feature tuning and CV-Grid Search \n",
    "\n",
    "# Code from: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rnd_clf_baseline = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random_clf = RandomizedSearchCV(estimator = rnd_clf_baseline, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985632183908046\n",
      "0.985632183908046\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_random_clf = rf_random_clf.best_estimator_\n",
    "y_pred_random = best_random_clf.predict(X_test)\n",
    "\n",
    "rnd_clf_baseline =  RandomForestClassifier(n_estimators = 1000, max_leaf_nodes = 10,random_state = 42)\n",
    "rnd_clf_baseline.fit(X_train, y_train)\n",
    "y_pred_baseline = rnd_clf_baseline.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_random))\n",
    "print(accuracy_score(y_test, y_pred_baseline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>VoteAlongRatio_Film</th>\n",
       "      <th>VoteAlongRatio_FS_IIR</th>\n",
       "      <th>VoteAlongRatio_FS_FSS</th>\n",
       "      <th>VoteAlongRatio_FS_CM</th>\n",
       "      <th>VoteAlongRatio_FS_REB</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>Year_2012</th>\n",
       "      <th>Year_2014</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_islander</th>\n",
       "      <th>ethnicity_native</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>party_short_D</th>\n",
       "      <th>party_short_R</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "      <th>Disney_Donations_Diff</th>\n",
       "      <th>Bloomberg_Donations_Diff</th>\n",
       "      <th>Citadel_Donations_Diff</th>\n",
       "      <th>Bloomberg_Donations_Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAINING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>48</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAINING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>48</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAINING</td>\n",
       "      <td>3061.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>50</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2400.0</td>\n",
       "      <td>-2400.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  VoteAlongRatio_Film  VoteAlongRatio_FS_IIR  \\\n",
       "192      48             0.000000               0.333333   \n",
       "193      48             0.333333               0.800000   \n",
       "194      48             0.600000               0.142857   \n",
       "200      50             0.800000               0.285714   \n",
       "202      50             0.500000               0.500000   \n",
       "\n",
       "     VoteAlongRatio_FS_FSS  VoteAlongRatio_FS_CM  VoteAlongRatio_FS_REB  \\\n",
       "192               0.333333              0.571429               0.666667   \n",
       "193               0.333333              0.400000               0.250000   \n",
       "194               0.333333              0.000000               0.000000   \n",
       "200               0.333333              0.000000               0.000000   \n",
       "202               0.666667              0.714286               0.666667   \n",
       "\n",
       "     sex_female  sex_male  Year_2012  Year_2014  ...  ethnicity_islander  \\\n",
       "192           0         1          1          0  ...                   0   \n",
       "193           0         1          0          1  ...                   0   \n",
       "194           0         1          0          0  ...                   0   \n",
       "200           1         0          0          0  ...                   0   \n",
       "202           1         0          1          0  ...                   0   \n",
       "\n",
       "     ethnicity_native  ethnicity_white  party_short_D  party_short_R  \\\n",
       "192                 0                0              1              0   \n",
       "193                 0                0              1              0   \n",
       "194                 0                0              1              0   \n",
       "200                 0                1              1              0   \n",
       "202                 0                1              1              0   \n",
       "\n",
       "     MODELING_GROUP  Disney_Donations_Diff  Bloomberg_Donations_Diff  \\\n",
       "192        TRAINING                    0.0                       0.0   \n",
       "193        TRAINING                    0.0                       0.0   \n",
       "194        TRAINING                 3061.0                      58.0   \n",
       "200         TESTING                    NaN                    7300.0   \n",
       "202         TESTING                    NaN                   -2400.0   \n",
       "\n",
       "     Citadel_Donations_Diff  Bloomberg_Donations_Dummy  \n",
       "192                     0.0                        1.0  \n",
       "193                     0.0                        1.0  \n",
       "194                    58.0                        2.0  \n",
       "200                  7300.0                        2.0  \n",
       "202                 -2400.0                        0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelgroups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#np.random.seed(42)\n",
    "#rnd_reg = RandomForestRegressor(n_estimators = 311, min_samples_split= 2, min_samples_leaf = 12, max_features = \"sqrt\", max_depth = 10, bootstrap = True)\n",
    "#from pprint import pprint\n",
    "#print('Parameters currently in use:\\n')\n",
    "#pprint(rnd_reg.get_params())\n",
    "#rnd_reg.fit(X_train, y_train)\n",
    "#y_pred = rnd_reg.predict(X_test)\n",
    "#from sklearn import metrics\n",
    "#print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "#print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "#print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [4, 8, 12],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Grid search for best tuned parameters: \n",
    "# Code taken from: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2 ,5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [4, 8, 12]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "{'n_estimators': 311, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 90, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Code taken from: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "#rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(rf_random.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error Baseline: 37.50325670498084\n",
      "Mean Absolute Error Random Best: 38.263669261424\n",
      "Mean Squared Error Baseline: 450631.2292911878\n",
      "Mean Squared Error Random Best: 445283.7053429075\n",
      "Root Mean Squared Error Baseline: 671.2907189073806\n",
      "Root Mean Squared Error Random Best: 667.2958154693521\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "from sklearn import metrics\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "y_pred_random = best_random.predict(X_test)\n",
    "\n",
    "rnd_reg_baseline = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "rnd_reg_baseline.fit(X_train, y_train)\n",
    "y_pred_baseline = rnd_reg_baseline.predict(X_test)\n",
    "\n",
    "\n",
    "print('Mean Absolute Error Baseline:', metrics.mean_absolute_error(y_test, y_pred_baseline))\n",
    "print('Mean Absolute Error Random Best:', metrics.mean_absolute_error(y_test, y_pred_random ))\n",
    "\n",
    "print('Mean Squared Error Baseline:', metrics.mean_squared_error(y_test, y_pred_baseline))\n",
    "print('Mean Squared Error Random Best:', metrics.mean_squared_error(y_test, y_pred_random ))\n",
    "\n",
    "print('Root Mean Squared Error Baseline:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_baseline)))\n",
    "print('Root Mean Squared Error Random Best:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_random )))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_reg_baseline = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "rnd_reg_baseline.fit(X_train, y_train)\n",
    "y_pred_baseline = rnd_reg_baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VoteAlongRatio_Film 0.10941264997170086\n",
      "VoteAlongRatio_FS_IIR 0.2032265795259661\n",
      "VoteAlongRatio_FS_FSS 0.10032444808630551\n",
      "VoteAlongRatio_FS_CM 0.13452676437617916\n",
      "VoteAlongRatio_FS_REB 0.10667983366085414\n",
      "sex_female 0.0884716368118809\n",
      "sex_male 0.014670859691930892\n",
      "ethnicity_asian 0.08036478365150433\n",
      "ethnicity_black 0.033051014840497474\n",
      "ethnicity_hispanic 0.005206977349648349\n",
      "ethnicity_islander 0.0\n",
      "ethnicity_native 0.0\n",
      "ethnicity_white 0.030283865463959725\n",
      "party_short_D 0.010408319969763175\n",
      "party_short_R 0.035640736160749656\n",
      "Year_2012 0.006250915987623727\n",
      "Year_2014 0.012457688187105423\n",
      "Year_2016 0.029022926264330423\n"
     ]
    }
   ],
   "source": [
    "# Get Feature Importance \n",
    "\n",
    "for name, score in zip(X_train.columns, rnd_reg_baseline.feature_importances_):\n",
    "    print(name, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling routines from Scikit Learn packages\n",
    "# import sklearn.linear_model\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LassoLarsIC\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV \n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures \n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting # noqa from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KernelDensity\n",
    "# Sanity check: Echo output so that we know that this critical first chu nk has run successfully\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 18 features, but DecisionTreeRegressor is expecting 22 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-8c61acebb44d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mforest_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[1;32m    403\u001b[0m                                     reset=False)\n\u001b[1;32m    404\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 18 features, but DecisionTreeRegressor is expecting 22 features as input."
     ]
    }
   ],
   "source": [
    "forest_predictions = best_random.predict(X_test)\n",
    "forest_weights = np.array(best_random.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie and doughnut plot ideas adapted freely from:\n",
    "# https://medium.com/@kvnamipara/a-better-visualisation-of-pie-charts-by-matplotlib-935b7667d77f\n",
    "# Conditional labeling code:\n",
    "# https://stackoverflow.com/questions/34035427/conditional-removal-of-labels-in-matplotlib-pie-chart/49753079\n",
    "def format_autopct(pct):\n",
    "    return ('%1.2f%%' % pct) if pct >= 2 else \"*\"\n",
    "\n",
    "def format_labels(sizes, labels):\n",
    "    new_labels = [label if size >= 0.02 else \"*\" for size, label in zip(sizes, labels)] \n",
    "    return new_labels\n",
    "\n",
    "def restore_matplotlib_defaults(): \n",
    "    sns.reset_defaults() \n",
    "    rc_file_defaults() \n",
    "    plt.rcParams[\"figure.dpi\"] = 72 \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doughnut_plot_sorted_feature_importances(model, feature_names, file_name = \"default\"):\n",
    "    n_features = len(model.feature_importances_)\n",
    "    importances = model.feature_importances_\n",
    "    sorted_index = np.argsort(importances)[::-1]\n",
    "    pie_labels = np.array(feature_names)[sorted_index]\n",
    "    #sns.set_palette(\"nipy_spectral_r\", n_colors = n_features) \n",
    "    fig, ax = plt.subplots(figsize = (16, 17))\n",
    "    ax.set_title(\"Model: \" + str(model).partition(\"(\")[0] + \"\\nSorted feature importances\", fontsize = 20)\n",
    "    ax.pie(importances[sorted_index], labeldistance = 1.04, pctdistance = 0.65,\n",
    "           labels = format_labels(importances[sorted_index], pie_labels),\n",
    "           startangle = 90,\n",
    "           counterclock = False, autopct = format_autopct, \n",
    "           wedgeprops = dict(linewidth = 3, edgecolor = \"white\"), \n",
    "           textprops = dict(color = \"black\", size = 16)) \n",
    "    \n",
    "    # weight = \"bold\",\n",
    "    # ax.legend(pie_labels, title = \"Features\", loc = \"center\", title_fontsize = 14,\n",
    "    #           facecolor = \"lightcyan\", fontsize = 12)\n",
    "    \n",
    "    \n",
    "    # Center circle\n",
    "    center_circle = plt.Circle((0, 0), 0.75, fc = \"white\")\n",
    "    fig = plt.gcf()\n",
    "    fig.gca().add_artist(center_circle)\n",
    "    \n",
    "    # Create legend\n",
    "    default_colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"] \n",
    "    patches = []\n",
    "    \n",
    "        \n",
    "    ax.legend(handles = patches, title = \"Feature Importances\", \n",
    "              loc = \"center\", facecolor = \"white\", \n",
    "              title_fontsize = 20, fontsize = 12)\n",
    "        \n",
    "        \n",
    "    #Equal aspect, then show the whole plot\n",
    "    ax.axis(\"equal\")\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_feature_names = X_train.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doughnut_plot_sorted_feature_importances(best_random, boston_feature_names, \"forest\")\n",
    "#plt.savefig(\"Disney_Regression_bestrandom_sorted_feature_importances_doughnut.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
